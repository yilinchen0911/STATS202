x/b^2*exp(-0.5*(x/b)^2)
}
cdf = function(x){
1-exp(-0.5*(x/b)^2)
}
u = 2
b = 2/(pi/2)^0.5
x = 0:100*0.1
plot(x,pdf(x),type = "l",ylab = "f(x)")
MC=10000;                            # Monte Carlo
y = rep(0,MC)
for( m in 1:MC){
x = runif(1)
y[m] = inversecdf(x)
}
hist(y,breaks = 0:100*0.1,freq = F)
points(x,pdf(x),type = "l")
MCmean = mean(y)
MCsigma = sd(y)
points(x,pdf(x),type = "l")
plot(x,pdf(x),type = "l")
pdf(x)
x
x
inversecdf = function(x){
b*(-2*log(1-x))^0.5
}
pdf = function(x){
x/b^2*exp(-0.5*(x/b)^2)
}
cdf = function(x){
1-exp(-0.5*(x/b)^2)
}
u = 2
b = 2/(pi/2)^0.5
x = 0:100*0.1
MC=10000;                            # Monte Carlo
y = rep(0,MC)
for( m in 1:MC){
u = runif(1)
y[m] = inversecdf(u)
}
hist(y,breaks = 0:100*0.1,freq = F)
points(x,pdf(x),type = "l")
install.packages("png")
library(tree)
install.packages("tree")
library(tree)
library(tree)
library(ISLR)
attach(Carseats)
train = sample(1:length(Carseats),length(Carseats)/2)
train
Carseats
length(Carseats)/2
library(tree)
library(ISLR)
attach(Carseats)
train = sample(1:nrow(Carseats),nrow(Carseats)/2)
library(tree)
library(ISLR)
attach(Carseats)
train = sample(1:nrow(Carseats),nrow(Carseats)/2)
train
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(1:nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
train
traindata = Carseats[train,]
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(1:nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
traindata = Carseats[train,]
testdata = Carseats[!train,]
traindata
testdata
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(1:nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
traindata = Carseats[train,]
testdata = Carseats[-train,]
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(1:nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
traindata = Carseats[train,]
testdata = Carseats[-train,]
View(testdata)
View(traindata)
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
traindata = Carseats[train,]
testdata = Carseats[-train,]
View(testdata)
View(traindata)
library(tree)
library(ISLR)
attach(Carseats)
set.seed(0)
train = sample(nrow(Carseats),nrow(Carseats)/2, replace = FALSE)
traindata = Carseats[train,]
testdata = Carseats[-train,]
tree.sales = tree(Sales~.,traindata)
summary(tree.sales)
plot(tree.sales)
text(tree.sales ,pretty =0)
predict(tree.sales, traindata)
tree.sales = tree(Sales~.,traindata)
summary(tree.sales)
plot(tree.sales)
text(tree.sales ,pretty =0)
mean((traindata - predict(tree.sales, traindata))^2)
tree.sales = tree(Sales~.,traindata)
summary(tree.sales)
plot(tree.sales)
text(tree.sales ,pretty =0)
mean((traindata$Sales - predict(tree.sales, traindata))^2)
tree.sales = tree(Sales~.,traindata)
summary(tree.sales)
plot(tree.sales)
text(tree.sales ,pretty =0)
mean((traindata$Sales - predict(tree.sales, traindata))^2)
mean((testdata$Sales - predict(tree.sales, testdata))^2)
cv.sales =cv.tree(tree.sales)
help(cv.tree)
cv.sales =cv.tree(tree.sales)
mean((testdata$Sales - predict(cv.sales, testdata))^2)
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales
prune.sales=prune.tree(tree.sales,best=13)
plot(prune.sales)
text(prune.sales,pretty=0)
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales
prune.sales=prune.tree(tree.sales,best=13)
par(mfrow = c(1,1))
plot(prune.sales)
text(prune.sales,pretty=0)
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales
prune.sales=prune.tree(tree.sales,best=13)
par(mfrow = c(1,1))
plot(prune.sales)
text(prune.sales,pretty=0)
mean((testdata$Sales - predict(prune.sales, testdata))^2)
set.seed(0)
cv.sales =cv.tree(tree.sales)
par(mfrow = c(1,2))
plot(cv.sales$size ,cv.sales$dev ,type="b")
plot(cv.sales$k ,cv.sales$dev ,type="b")
cv.sales
prune.sales=prune.tree(tree.sales,best=13)
par(mfrow = c(1,1))
plot(prune.sales)
text(prune.sales,pretty=0)
mean((testdata$Sales - predict(prune.sales, testdata))^2)
install.packages("randomForest")
library(randomForest)
set.seed(0)
bag.sale=randomForest(Salesâˆ¼.,data = traindata,mtry=13,importance =TRUE)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=13,importance =TRUE)
ncol(traindata)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=7,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=5,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=4,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=8,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
library(randomForest)
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=ncol(traindata)-1,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=7,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
## We use m =7 in this case
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=7,importance =TRUE)
mean((testdata$Sales - predict(bag.sale, testdata))^2)
importance(bag.sale)
testerror = rep(NA,10)
for (i in 1:10) {
set.seed(0)
bag.sale=randomForest(Sales~.,data = traindata,mtry=i,importance =TRUE)
testerror[i] = mean((testdata$Sales - predict(bag.sale, testdata))^2)
}
testerror
Hitters
which(Hitters$Salary != NA)
if(Hitters$Salary != NA)
)
Hitters$Salary != NA
Hitters
Hitters$Salary == NA
Hitters$Salary
Hitters$Salary == 400
Hitters$Salary == NA
is.na(Hitters$Salary)
data = Hitters[!is.na(Hitters$Salary),]
attach(data)
data
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
log(nonnaHitters$Salary,10)
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
logHitters = data.frame(nonnaHitters[,-"Salary"],log(nonnaHitters$Salary,10))
attach(logHitters)
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
logHitters = data.frame(nonnaHitters[,-Salary],log(nonnaHitters$Salary,10))
attach(logHitters)
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
logHitters = data.frame(nonnaHitters[,-Salary],log(nonnaHitters$Salary))
attach(logHitters)
logHitters
nonnaHitters[,-Salary]
log(nonnaHitters$Salary)
nonnaHitters[,-Salary]
ncol(Hitters)
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
logHitters = data.frame(nonnaHitters[,-19],log(nonnaHitters$Salary))
attach(logHitters)
logHitters
colnames(logHitters)
nonnaHitters = Hitters[!is.na(Hitters$Salary),]
logHitters = data.frame(nonnaHitters[,-19],log(nonnaHitters$Salary))
colnames(logHitters)[20] = "Salary"
attach(logHitters)
logHitters
train = 1:200
traindata = logHitters[train,]
testdata = logHitters[-train,]
install.packages("gym")
library(gbm)
set.seed(0)
trainerror = rep(NA,200)
b =
for (i in 1:10) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian ",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((i-10)/3,trainerror)
install.packages("gbm")
library(gbm)
set.seed(0)
trainerror = rep(NA,200)
b =
for (i in 1:10) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian ",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((i-10)/3,trainerror)
library(gbm)
set.seed(0)
trainerror = rep(NA,200)
b =
for (i in 1:10) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((i-10)/3,trainerror)
library(gbm)
set.seed(0)
trainerror = rep(NA,200)
for (i in 1:10) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((1:10-10)/3,trainerror)
library(gbm)
set.seed(0)
trainerror = rep(NA,200)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror)
trainerror
library(gbm)
set.seed(0)
trainerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror)
library(gbm)
set.seed(0)
trainerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror,type = "b")
library(gbm)
set.seed(0)
trainerror = rep(NA,19)
b = 1:19
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-19)/6))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror,type = "b")
library(gbm)
set.seed(0)
trainerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror,type = "b")
plot(10^((b-10)/3),trainerror,type = "o")
library(gbm)
set.seed(0)
trainerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=traindata, n.trees=1000)
trainerror[i] = mean((pred - traindata$Salary)^2)
}
plot(10^((b-10)/3),trainerror,type = "o",xlab = "Shrinkage", ylab = "Train MSE")
set.seed(0)
testerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=testdata, n.trees=1000)
testerror[i] = mean((pred - testdata$Salary)^2)
}
plot(10^((b-10)/3),testerror,type = "o",xlab = "Shrinkage", ylab = "Trainning MSE")
set.seed(0)
testerror = rep(NA,10)
b = 1:10
for (i in b) {
boost.boston=gbm(Salary~.,data=traindata,distribution="gaussian",
n.trees=1000,interaction.depth=2,shrinkage =10^((i-10)/3))
pred=predict(boost.boston,data=testdata, n.trees=1000)
testerror[i] = mean((pred - testdata$Salary)^2)
}
plot(10^((b-10)/3),testerror,type = "o",xlab = "Shrinkage", ylab = "Test MSE")
read.csv("train.csv")
read.csv("train.csv")
read.csv("train.csv")
sd
setwd("~/Desktop/STATS 202/Kaggle")
read.csv("train.csv")
pairs(A)
A = read.csv("train.csv")
pairs(A)
pairs(B)
A = read.csv("train.csv")
pairs(A)
B = A [-5,]
pairs(B)
A = read.csv("train.csv")
pairs(A)
B = A [-5,]
pairs(B)
attach(B)
lm.fit = lm(Value~., data = B)
plot(lm.fit)
par(mfrow = c(2,2))
plot(lm.fit)
test = read.csv("test.csv")
predict(lm.fit, newdata = test)
predict(lm.fit, newdata = test)
predict(lm.fit, data = test)
predict(lm.fit, newdata = test)
predict(lm.fit, data = test)
predict(lm.fit, test)
predict(lm.fit, list(test))
predict(lm.fit, list(test))
predict(lm.fit, newdata = list(test))
predict(lm.fit, newdata = list(test))
predict(lm.fit, newdata = test)
View(test)
predict(lm.fit, test)
A = read.csv("train.csv")
pairs(A)
B = A [-5,]
pairs(B)
attach(B)
lm.fit = lm(Value~., data = B)
test = read.csv("test.csv")
predict(lm.fit, newdata = test)
A = read.csv("train.csv")
pairs(A)
B = A [-c(1, 5),]
pairs(B)
attach(B)
lm.fit = lm(Value~., data = B)
test = read.csv("test.csv")
predict(lm.fit, newdata = test)
A = read.csv("train.csv")
B = A [-c(1, 5),]
lm.fit = lm(Value~., data = B)
test = read.csv("test.csv")
predict(lm.fit, newdata = test)
View(B)
pred =predict(lm.fit, newdata = test)
View(B)
View(test)
A = read.csv("train.csv")
B = A [-c(1, 5), -8]
lm.fit = lm(Value~., data = B)
test = read.csv("test.csv")
test = test[,-8]
pred = predict(lm.fit, newdata = test)
A = read.csv("train.csv")
B = A [-c(1, 5),-8]
lm.fit = lm(Value~., data = B)
test = read.csv("test.csv")
test = test[,]
pred = predict(lm.fit, newdata = test)
pred
